{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newspaper import Article\n",
    "import newspaper\n",
    "from newspaper import news_pool\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting default working directory\n",
    "os.chdir('C:/Users/Hetal/Desktop/SJSU/CMPE - 255/Project/bbc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of news papers to crawl and the categories to look for\n",
    "\n",
    "papers_dict = {   \n",
    "    'BBC': {\n",
    "        'URL':'http://www.bbc.com',\n",
    "    },\n",
    "    'BBC_UK': {\n",
    "        'URL':'http://www.bbc.co.uk',\n",
    "    },\n",
    "    'SLATE': {\n",
    "        'URL':'http://www.slate.com',\n",
    "    },\n",
    "    'GUARDIAN': {\n",
    "        'URL':'http://www.theguardian.com',\n",
    "    },\n",
    "    'BREITBRAT': {\n",
    "        'URL':'http://www.breitbart.com',\n",
    "    },\n",
    "    'NBC': {\n",
    "        'URL':'http://www.nbcnews.com',\n",
    "    },\n",
    "    'WASHINGTONPOST': {\n",
    "        'URL':'http://www.washingtonpost.com',\n",
    "    },\n",
    "    'USNEWS': {\n",
    "        'URL':'http://www.usnews.com/', \n",
    "    },\n",
    "    'NYTIMES': {\n",
    "        'URL':'http://www.nytimes.com/', \n",
    "    },\n",
    "    'USATODAY': {\n",
    "        'URL':'http://www.usatoday.com/', \n",
    "    },\n",
    "    'NYDAILYNEWS': {\n",
    "        'URL':'http://www.nydailynews.com', \n",
    "    },\n",
    "    'LATIMES': {\n",
    "        'URL':'http://www.latimes.com/', \n",
    "    },\n",
    "    'WALLSTREETJOURNAL': {\n",
    "        'URL':'http://www.wsj.com/', \n",
    "    },\n",
    "    'BUSINESS_STANDARD': {\n",
    "        'URL':'http://www.business-standard.com/', \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadContent(paper):\n",
    "\n",
    "    patterns = ['/politics/','/tech/','/technology/','/sport/','/sports/','/business/','/entertainment/','/world/']\n",
    "    type = []\n",
    "    news = []\n",
    "    url =  []\n",
    "    count = 0\n",
    "    for article in paper.articles:\n",
    "        try:\n",
    "            for pattern in patterns:\n",
    "                if(re.search(pattern,article.url)):\n",
    "                    if article.url not in url:\n",
    "                        article.download()\n",
    "                        article.parse()\n",
    "                        if(len(article.text) > 350 and len(article.text)<6000):\n",
    "                            news.append(article.text)\n",
    "                            type.append(pattern[1:-1])\n",
    "                            count = count + 1\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    print(\"No of articles crawled : \", count);\n",
    "    combined_data = {'category': type, 'news': news}\n",
    "    dataset = pd.DataFrame(combined_data)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling from:  http://www.bbc.com\n",
      "No of articles crawled :  9\n",
      "Crawling from:  http://www.bbc.co.uk\n",
      "No of articles crawled :  6\n",
      "Crawling from:  http://www.slate.com\n",
      "No of articles crawled :  13\n",
      "Crawling from:  http://www.theguardian.com\n",
      "No of articles crawled :  31\n",
      "Crawling from:  http://www.breitbart.com\n",
      "No of articles crawled :  298\n",
      "Crawling from:  http://www.nbcnews.com\n",
      "No of articles crawled :  0\n",
      "Crawling from:  http://www.washingtonpost.com\n",
      "No of articles crawled :  25\n",
      "Crawling from:  http://www.usnews.com/\n",
      "No of articles crawled :  13\n",
      "Crawling from:  http://www.nytimes.com/\n",
      "No of articles crawled :  24\n",
      "Crawling from:  http://www.usatoday.com/\n",
      "No of articles crawled :  150\n",
      "Crawling from:  http://www.nydailynews.com\n",
      "No of articles crawled :  32\n",
      "Crawling from:  http://www.latimes.com/\n",
      "No of articles crawled :  19\n",
      "Crawling from:  http://www.wsj.com/\n",
      "No of articles crawled :  1\n",
      "Crawling from:  http://www.business-standard.com/\n",
      "No of articles crawled :  52\n"
     ]
    }
   ],
   "source": [
    "result = pd.DataFrame()\n",
    "for name,value in papers_dict.items():\n",
    "    print(\"Crawling from: \", value['URL'])\n",
    "    paper = newspaper.build(value['URL'],memoize_articles=False, language = 'en')\n",
    "    df = downloadContent(paper)\n",
    "    result = pd.concat([df, result], ignore_index=True, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping ALL duplicte values \n",
    "result.drop_duplicates(subset =\"news\", \n",
    "                     keep = \"first\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 443 entries, 0 to 669\n",
      "Data columns (total 2 columns):\n",
      "category    443 non-null object\n",
      "news        443 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 10.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "politics         135\n",
       "sports           106\n",
       "technology        69\n",
       "entertainment     69\n",
       "world             33\n",
       "business          31\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.info()\n",
    "result.loc[(result.category == 'tech'),'category']='technology'\n",
    "result.loc[(result.category == 'sport'),'category']='sports'\n",
    "result['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('../test2.csv', encoding=\"utf-8-sig\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../dataset.csv', 'a+', encoding=\"utf-8-sig\", newline='') as f:\n",
    "    result.to_csv(f, header=False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../test4.csv', 'a+', encoding=\"utf-8-sig\", newline='') as f:\n",
    "    result.to_csv(f, header=False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 437 entries, 0 to 667\n",
      "Data columns (total 3 columns):\n",
      "category    437 non-null object\n",
      "news        437 non-null object\n",
      "url         437 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 13.7+ KB\n"
     ]
    }
   ],
   "source": [
    "result.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
