{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx\n",
    "import rouge\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "os.chdir('../Preprocessing')\n",
    "from normalization import normalize_corpus, parse_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>SUMMARY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>The Federal Reserve approved Ally Financial In...</td>\n",
       "      <td>The Federal Reserve approved Ally Financial In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>— Major shareholders of Duke Energy Corp. have...</td>\n",
       "      <td>— Major shareholders of Duke Energy Corp. have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>Photos taken earlier this month show that Nort...</td>\n",
       "      <td>Photos taken earlier this month show that Nort...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>Thanks to dogged reporting by the Associated P...</td>\n",
       "      <td>Thanks to dogged reporting by the Associated P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>The energy giant says it is committed to clean...</td>\n",
       "      <td>The energy giant says it is committed to clean...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CATEGORY                                            CONTENT  \\\n",
       "0  business  The Federal Reserve approved Ally Financial In...   \n",
       "1  business  — Major shareholders of Duke Energy Corp. have...   \n",
       "2  business  Photos taken earlier this month show that Nort...   \n",
       "3  business  Thanks to dogged reporting by the Associated P...   \n",
       "4  business  The energy giant says it is committed to clean...   \n",
       "\n",
       "                                             SUMMARY  \n",
       "0  The Federal Reserve approved Ally Financial In...  \n",
       "1  — Major shareholders of Duke Energy Corp. have...  \n",
       "2  Photos taken earlier this month show that Nort...  \n",
       "3  Thanks to dogged reporting by the Associated P...  \n",
       "4  The energy giant says it is committed to clean...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Data_collection/dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FILTERED_CONTENT'] = df['CONTENT'].apply(parse_content)\n",
    "df['length'] =df['FILTERED_CONTENT'].apply(len)\n",
    "df = df[df['length']>15]\n",
    "df.drop('length',axis =1 ,inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 999 entries, 3 to 1992\n",
      "Data columns (total 4 columns):\n",
      "CATEGORY            999 non-null object\n",
      "CONTENT             999 non-null object\n",
      "SUMMARY             999 non-null object\n",
      "FILTERED_CONTENT    999 non-null object\n",
      "dtypes: object(4)\n",
      "memory usage: 39.0+ KB\n"
     ]
    }
   ],
   "source": [
    "#Taking a subset of the data:\n",
    "df=df.iloc[1:1000]\n",
    "\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>SUMMARY</th>\n",
       "      <th>FILTERED_CONTENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>Thanks to dogged reporting by the Associated P...</td>\n",
       "      <td>Thanks to dogged reporting by the Associated P...</td>\n",
       "      <td>[thanks dog report associated press know activ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>business</td>\n",
       "      <td>RALEIGH, N.C., March 26 (Reuters) - Duke Energ...</td>\n",
       "      <td>In a letter to the state’s utilities commissio...</td>\n",
       "      <td>[raleigh march reuters duke energy corp say we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>business</td>\n",
       "      <td>CHARLOTTE, N.C., March 26, 2014 /PRNewswire/ -...</td>\n",
       "      <td>Throughout the past few decades, we have dedic...</td>\n",
       "      <td>[charlotte march duke energy nyse duk today is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>business</td>\n",
       "      <td>By Suttinee Yuvejwattana and Michael Sin\\n\\nMa...</td>\n",
       "      <td>The Japanese satellite detected about a dozen ...</td>\n",
       "      <td>[by suttinee yuvejwattana michael sin, march b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>business</td>\n",
       "      <td>PERTH, Australia (AP) � Planes and ships searc...</td>\n",
       "      <td>PERTH, Australia (AP) � Planes and ships searc...</td>\n",
       "      <td>[perth australia ap plane ship search debris s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CATEGORY                                            CONTENT  \\\n",
       "3   business  Thanks to dogged reporting by the Associated P...   \n",
       "6   business  RALEIGH, N.C., March 26 (Reuters) - Duke Energ...   \n",
       "9   business  CHARLOTTE, N.C., March 26, 2014 /PRNewswire/ -...   \n",
       "11  business  By Suttinee Yuvejwattana and Michael Sin\\n\\nMa...   \n",
       "12  business  PERTH, Australia (AP) � Planes and ships searc...   \n",
       "\n",
       "                                              SUMMARY  \\\n",
       "3   Thanks to dogged reporting by the Associated P...   \n",
       "6   In a letter to the state’s utilities commissio...   \n",
       "9   Throughout the past few decades, we have dedic...   \n",
       "11  The Japanese satellite detected about a dozen ...   \n",
       "12  PERTH, Australia (AP) � Planes and ships searc...   \n",
       "\n",
       "                                     FILTERED_CONTENT  \n",
       "3   [thanks dog report associated press know activ...  \n",
       "6   [raleigh march reuters duke energy corp say we...  \n",
       "9   [charlotte march duke energy nyse duk today is...  \n",
       "11  [by suttinee yuvejwattana michael sin, march b...  \n",
       "12  [perth australia ap plane ship search debris s...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['FILTERED_CONTENT'] = df['FILTERED_CONTENT'].apply(normalize_corpus)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Rank Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textrank_text_summarizer(data):\n",
    "    \n",
    "    text =data[3]\n",
    "    sentences = [sent for sent in nltk.sent_tokenize(data[1])]\n",
    "    summary = [sent for sent in nltk.sent_tokenize(data[2])]\n",
    "    num_sentences = len(summary)\n",
    "    print(len(text),\"----\",num_sentences)\n",
    "    bow_matrix = CountVectorizer().fit_transform(text)\n",
    "\n",
    "    dt_matrix = TfidfTransformer().fit_transform(bow_matrix)\n",
    "\n",
    "    similarity_matrix = (dt_matrix * dt_matrix.T)\n",
    "    similarity_graph = networkx.from_scipy_sparse_matrix(similarity_matrix)\n",
    "    \n",
    "    scores = networkx.pagerank(similarity_graph)   \n",
    "    ranked_sentences = sorted(((score, index) \n",
    "                                for index, score \n",
    "                                in scores.items()), \n",
    "                              reverse=True)\n",
    "    try:\n",
    "        top_sentence_indices = [ranked_sentences[index][1] for index in range(num_sentences)]\n",
    "        top_sentence_indices.sort()\n",
    "        top_sentences = [sentences[index] for index in top_sentence_indices]\n",
    "        summary =''.join(top_sentences)\n",
    "        return summary\n",
    "    except IndexError:\n",
    "        pass\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 ---- 5\n",
      "17 ---- 5\n",
      "39 ---- 5\n",
      "19 ---- 5\n",
      "19 ---- 5\n",
      "23 ---- 5\n",
      "31 ---- 5\n",
      "27 ---- 5\n",
      "24 ---- 5\n",
      "23 ---- 5\n",
      "29 ---- 5\n",
      "19 ---- 5\n",
      "43 ---- 5\n",
      "45 ---- 5\n",
      "23 ---- 5\n",
      "18 ---- 5\n",
      "21 ---- 5\n",
      "17 ---- 5\n",
      "36 ---- 5\n",
      "27 ---- 5\n",
      "16 ---- 5\n",
      "23 ---- 5\n",
      "32 ---- 5\n",
      "22 ---- 5\n",
      "42 ---- 5\n",
      "21 ---- 5\n",
      "16 ---- 5\n",
      "42 ---- 5\n",
      "48 ---- 5\n",
      "33 ---- 5\n",
      "45 ---- 5\n",
      "50 ---- 5\n",
      "37 ---- 5\n",
      "18 ---- 5\n",
      "24 ---- 5\n",
      "30 ---- 5\n",
      "25 ---- 5\n",
      "44 ---- 5\n",
      "30 ---- 5\n",
      "18 ---- 5\n",
      "19 ---- 5\n",
      "23 ---- 5\n",
      "34 ---- 5\n",
      "35 ---- 5\n",
      "37 ---- 5\n",
      "41 ---- 5\n",
      "27 ---- 5\n",
      "47 ---- 5\n",
      "20 ---- 5\n",
      "43 ---- 5\n",
      "50 ---- 5\n",
      "44 ---- 5\n",
      "22 ---- 5\n",
      "29 ---- 5\n",
      "16 ---- 5\n",
      "19 ---- 5\n",
      "16 ---- 5\n",
      "52 ---- 5\n",
      "18 ---- 5\n",
      "23 ---- 5\n",
      "16 ---- 5\n",
      "38 ---- 5\n",
      "16 ---- 5\n",
      "24 ---- 5\n",
      "32 ---- 5\n",
      "26 ---- 5\n",
      "33 ---- 5\n",
      "27 ---- 5\n",
      "18 ---- 5\n",
      "17 ---- 5\n",
      "54 ---- 5\n",
      "48 ---- 5\n",
      "21 ---- 5\n",
      "17 ---- 5\n",
      "58 ---- 5\n",
      "26 ---- 5\n",
      "42 ---- 5\n",
      "27 ---- 5\n",
      "36 ---- 5\n",
      "28 ---- 5\n",
      "35 ---- 5\n",
      "19 ---- 5\n",
      "19 ---- 5\n",
      "41 ---- 5\n",
      "16 ---- 5\n",
      "41 ---- 5\n",
      "17 ---- 5\n",
      "36 ---- 5\n",
      "26 ---- 5\n",
      "42 ---- 5\n",
      "17 ---- 5\n",
      "26 ---- 5\n",
      "26 ---- 5\n",
      "25 ---- 5\n",
      "18 ---- 5\n",
      "19 ---- 5\n",
      "46 ---- 5\n",
      "20 ---- 5\n",
      "24 ---- 5\n",
      "23 ---- 5\n",
      "17 ---- 5\n",
      "27 ---- 5\n",
      "33 ---- 5\n",
      "29 ---- 5\n",
      "48 ---- 5\n",
      "29 ---- 5\n",
      "45 ---- 5\n",
      "29 ---- 5\n",
      "19 ---- 5\n",
      "29 ---- 5\n",
      "20 ---- 5\n",
      "28 ---- 5\n",
      "25 ---- 5\n",
      "31 ---- 5\n",
      "18 ---- 5\n",
      "42 ---- 5\n",
      "37 ---- 5\n",
      "26 ---- 5\n",
      "23 ---- 5\n",
      "17 ---- 5\n",
      "32 ---- 5\n",
      "26 ---- 5\n",
      "16 ---- 5\n",
      "37 ---- 5\n",
      "17 ---- 5\n",
      "29 ---- 5\n",
      "28 ---- 5\n",
      "42 ---- 5\n",
      "32 ---- 5\n",
      "24 ---- 5\n",
      "19 ---- 5\n",
      "18 ---- 5\n",
      "20 ---- 5\n",
      "21 ---- 5\n",
      "31 ---- 5\n",
      "17 ---- 5\n",
      "16 ---- 5\n",
      "23 ---- 5\n",
      "18 ---- 5\n",
      "33 ---- 5\n",
      "39 ---- 5\n",
      "24 ---- 5\n",
      "37 ---- 5\n",
      "20 ---- 5\n",
      "21 ---- 5\n",
      "28 ---- 5\n",
      "33 ---- 5\n",
      "30 ---- 5\n",
      "24 ---- 5\n",
      "28 ---- 5\n",
      "17 ---- 5\n",
      "26 ---- 5\n",
      "19 ---- 5\n",
      "17 ---- 5\n",
      "16 ---- 5\n",
      "24 ---- 5\n",
      "19 ---- 5\n",
      "50 ---- 5\n",
      "37 ---- 5\n",
      "28 ---- 5\n",
      "23 ---- 5\n",
      "39 ---- 5\n",
      "25 ---- 5\n",
      "42 ---- 5\n",
      "43 ---- 5\n",
      "25 ---- 5\n",
      "18 ---- 5\n",
      "34 ---- 5\n",
      "20 ---- 5\n",
      "28 ---- 5\n",
      "25 ---- 5\n",
      "29 ---- 5\n",
      "24 ---- 5\n",
      "20 ---- 5\n",
      "36 ---- 5\n",
      "28 ---- 5\n",
      "16 ---- 5\n",
      "18 ---- 5\n",
      "17 ---- 5\n",
      "48 ---- 5\n",
      "31 ---- 5\n",
      "30 ---- 5\n",
      "21 ---- 5\n",
      "26 ---- 5\n",
      "22 ---- 5\n",
      "18 ---- 5\n",
      "16 ---- 5\n",
      "35 ---- 5\n",
      "41 ---- 5\n",
      "17 ---- 5\n",
      "17 ---- 5\n",
      "19 ---- 5\n",
      "57 ---- 5\n",
      "19 ---- 5\n",
      "23 ---- 5\n",
      "21 ---- 5\n",
      "19 ---- 5\n",
      "17 ---- 5\n",
      "27 ---- 5\n",
      "28 ---- 5\n",
      "22 ---- 5\n",
      "24 ---- 5\n",
      "22 ---- 5\n",
      "25 ---- 5\n",
      "23 ---- 5\n",
      "23 ---- 5\n",
      "22 ---- 5\n",
      "22 ---- 5\n",
      "30 ---- 5\n",
      "30 ---- 5\n",
      "33 ---- 5\n",
      "22 ---- 5\n",
      "17 ---- 5\n",
      "45 ---- 5\n",
      "40 ---- 5\n",
      "25 ---- 5\n",
      "25 ---- 5\n",
      "25 ---- 5\n",
      "25 ---- 5\n",
      "21 ---- 5\n",
      "17 ---- 5\n",
      "19 ---- 5\n",
      "50 ---- 5\n",
      "17 ---- 5\n",
      "22 ---- 5\n",
      "16 ---- 5\n",
      "24 ---- 5\n",
      "31 ---- 5\n",
      "16 ---- 5\n",
      "20 ---- 5\n",
      "19 ---- 5\n",
      "18 ---- 5\n",
      "16 ---- 5\n",
      "18 ---- 5\n",
      "20 ---- 5\n",
      "18 ---- 5\n",
      "16 ---- 5\n",
      "28 ---- 5\n",
      "19 ---- 5\n",
      "20 ---- 5\n",
      "31 ---- 5\n",
      "46 ---- 5\n",
      "48 ---- 5\n",
      "35 ---- 5\n",
      "24 ---- 5\n",
      "17 ---- 5\n",
      "24 ---- 5\n",
      "37 ---- 5\n",
      "24 ---- 5\n",
      "16 ---- 5\n",
      "23 ---- 5\n",
      "27 ---- 5\n",
      "23 ---- 5\n",
      "18 ---- 5\n",
      "46 ---- 5\n",
      "24 ---- 5\n",
      "39 ---- 5\n",
      "26 ---- 5\n",
      "36 ---- 5\n",
      "35 ---- 5\n",
      "39 ---- 5\n",
      "23 ---- 5\n",
      "22 ---- 5\n",
      "46 ---- 5\n",
      "46 ---- 5\n",
      "28 ---- 5\n",
      "32 ---- 5\n",
      "20 ---- 5\n",
      "43 ---- 5\n",
      "48 ---- 5\n",
      "44 ---- 5\n",
      "43 ---- 5\n",
      "38 ---- 5\n",
      "19 ---- 5\n",
      "36 ---- 5\n",
      "39 ---- 5\n",
      "22 ---- 5\n",
      "16 ---- 5\n",
      "38 ---- 5\n",
      "22 ---- 5\n",
      "40 ---- 5\n",
      "25 ---- 5\n",
      "46 ---- 5\n",
      "33 ---- 5\n",
      "50 ---- 5\n",
      "16 ---- 5\n",
      "18 ---- 5\n",
      "17 ---- 5\n",
      "17 ---- 4\n",
      "21 ---- 5\n",
      "22 ---- 5\n",
      "17 ---- 5\n",
      "31 ---- 5\n",
      "27 ---- 5\n",
      "21 ---- 5\n",
      "25 ---- 5\n",
      "35 ---- 5\n",
      "26 ---- 5\n",
      "35 ---- 5\n",
      "18 ---- 5\n",
      "22 ---- 5\n",
      "43 ---- 5\n",
      "16 ---- 5\n",
      "37 ---- 5\n",
      "26 ---- 5\n",
      "18 ---- 5\n",
      "37 ---- 5\n",
      "38 ---- 5\n",
      "21 ---- 5\n",
      "23 ---- 5\n",
      "18 ---- 5\n",
      "21 ---- 5\n",
      "23 ---- 5\n",
      "23 ---- 5\n",
      "36 ---- 5\n",
      "51 ---- 5\n",
      "24 ---- 5\n",
      "33 ---- 5\n",
      "35 ---- 5\n",
      "24 ---- 5\n",
      "23 ---- 5\n",
      "17 ---- 5\n",
      "29 ---- 5\n",
      "49 ---- 5\n",
      "27 ---- 5\n",
      "17 ---- 5\n",
      "22 ---- 5\n",
      "47 ---- 5\n",
      "17 ---- 5\n",
      "25 ---- 5\n",
      "24 ---- 5\n",
      "29 ---- 5\n",
      "22 ---- 5\n",
      "20 ---- 5\n",
      "35 ---- 5\n",
      "16 ---- 5\n",
      "34 ---- 5\n",
      "21 ---- 5\n",
      "44 ---- 5\n",
      "23 ---- 5\n",
      "16 ---- 5\n",
      "35 ---- 5\n",
      "16 ---- 5\n",
      "32 ---- 5\n",
      "39 ---- 5\n",
      "27 ---- 5\n",
      "25 ---- 5\n",
      "20 ---- 5\n",
      "34 ---- 5\n",
      "49 ---- 5\n",
      "32 ---- 5\n",
      "17 ---- 5\n",
      "39 ---- 5\n",
      "19 ---- 5\n",
      "20 ---- 5\n",
      "17 ---- 5\n",
      "32 ---- 5\n",
      "18 ---- 5\n",
      "35 ---- 5\n",
      "35 ---- 5\n",
      "22 ---- 5\n",
      "31 ---- 5\n",
      "16 ---- 5\n",
      "38 ---- 5\n",
      "17 ---- 5\n",
      "27 ---- 5\n",
      "33 ---- 5\n",
      "19 ---- 5\n",
      "33 ---- 5\n",
      "36 ---- 5\n",
      "35 ---- 5\n",
      "25 ---- 5\n",
      "36 ---- 5\n",
      "33 ---- 5\n",
      "23 ---- 5\n",
      "24 ---- 5\n",
      "29 ---- 5\n",
      "22 ---- 5\n",
      "36 ---- 5\n",
      "35 ---- 5\n",
      "18 ---- 5\n",
      "16 ---- 5\n",
      "31 ---- 5\n",
      "34 ---- 5\n",
      "52 ---- 5\n",
      "35 ---- 5\n",
      "35 ---- 5\n",
      "53 ---- 5\n",
      "18 ---- 5\n",
      "33 ---- 5\n",
      "18 ---- 5\n",
      "30 ---- 5\n",
      "49 ---- 5\n",
      "21 ---- 5\n",
      "19 ---- 5\n",
      "27 ---- 5\n",
      "18 ---- 5\n",
      "22 ---- 5\n",
      "25 ---- 5\n",
      "32 ---- 5\n",
      "56 ---- 5\n",
      "54 ---- 5\n",
      "20 ---- 5\n",
      "52 ---- 5\n",
      "24 ---- 5\n",
      "48 ---- 5\n",
      "34 ---- 5\n",
      "33 ---- 5\n",
      "34 ---- 5\n",
      "31 ---- 5\n",
      "29 ---- 5\n",
      "21 ---- 5\n",
      "22 ---- 5\n",
      "22 ---- 5\n",
      "35 ---- 5\n",
      "28 ---- 5\n",
      "16 ---- 5\n",
      "31 ---- 5\n",
      "31 ---- 5\n",
      "31 ---- 5\n",
      "33 ---- 5\n",
      "19 ---- 5\n",
      "19 ---- 5\n",
      "38 ---- 5\n",
      "24 ---- 5\n",
      "22 ---- 5\n",
      "24 ---- 5\n",
      "16 ---- 5\n",
      "18 ---- 5\n",
      "27 ---- 5\n",
      "23 ---- 5\n",
      "28 ---- 5\n",
      "16 ---- 5\n",
      "25 ---- 5\n",
      "44 ---- 5\n",
      "31 ---- 5\n",
      "33 ---- 5\n",
      "28 ---- 5\n",
      "22 ---- 5\n",
      "35 ---- 5\n",
      "26 ---- 5\n",
      "27 ---- 5\n",
      "18 ---- 5\n",
      "20 ---- 5\n",
      "16 ---- 5\n",
      "17 ---- 5\n",
      "35 ---- 5\n",
      "23 ---- 5\n",
      "16 ---- 5\n",
      "22 ---- 5\n",
      "27 ---- 5\n",
      "17 ---- 5\n",
      "20 ---- 5\n",
      "29 ---- 5\n",
      "18 ---- 5\n",
      "23 ---- 5\n",
      "34 ---- 5\n",
      "23 ---- 5\n",
      "27 ---- 5\n",
      "39 ---- 5\n",
      "34 ---- 5\n",
      "35 ---- 5\n",
      "31 ---- 5\n",
      "24 ---- 5\n",
      "20 ---- 5\n",
      "22 ---- 5\n",
      "36 ---- 5\n",
      "17 ---- 5\n",
      "34 ---- 5\n",
      "36 ---- 5\n",
      "25 ---- 5\n",
      "24 ---- 5\n",
      "25 ---- 5\n",
      "27 ---- 5\n",
      "19 ---- 5\n",
      "24 ---- 5\n",
      "41 ---- 5\n",
      "47 ---- 5\n",
      "21 ---- 5\n",
      "57 ---- 5\n",
      "34 ---- 5\n",
      "36 ---- 5\n",
      "23 ---- 5\n",
      "43 ---- 5\n",
      "26 ---- 5\n",
      "28 ---- 5\n",
      "47 ---- 5\n",
      "19 ---- 5\n",
      "18 ---- 5\n",
      "19 ---- 5\n",
      "17 ---- 5\n",
      "24 ---- 5\n",
      "19 ---- 5\n",
      "19 ---- 5\n",
      "18 ---- 5\n",
      "18 ---- 5\n",
      "26 ---- 5\n",
      "33 ---- 5\n",
      "28 ---- 5\n",
      "28 ---- 5\n",
      "34 ---- 5\n",
      "34 ---- 5\n",
      "22 ---- 5\n",
      "31 ---- 5\n",
      "22 ---- 5\n",
      "23 ---- 5\n"
     ]
    }
   ],
   "source": [
    "df['Generated_Summary']= df.apply(textrank_text_summarizer,axis =1)\n",
    "df.dropna(subset = ['Generated_Summary'],inplace=True)\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation with Avg\n",
      "\trouge-1:\tP: 52.49\tR: 51.07\tF1: 51.13\n",
      "\trouge-2:\tP: 35.90\tR: 35.15\tF1: 35.17\n",
      "\trouge-3:\tP: 32.63\tR: 31.95\tF1: 31.97\n",
      "\trouge-4:\tP: 31.11\tR: 30.48\tF1: 30.49\n",
      "\n",
      "Evaluation with Best\n",
      "\trouge-1:\tP: 52.49\tR: 51.07\tF1: 51.13\n",
      "\trouge-2:\tP: 35.90\tR: 35.15\tF1: 35.17\n",
      "\trouge-3:\tP: 32.63\tR: 31.95\tF1: 31.97\n",
      "\trouge-4:\tP: 31.11\tR: 30.48\tF1: 30.49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hypothesis = df['Generated_Summary'].tolist()\n",
    "reference = df['SUMMARY'].tolist()\n",
    "\n",
    "def prepare_results(p, r, f):\n",
    "    return '\\t{}:\\t{}: {:5.2f}\\t{}: {:5.2f}\\t{}: {:5.2f}'.format(metric, 'P', 100.0 * p, 'R', 100.0 * r, 'F1', 100.0 * f)\n",
    "\n",
    "\n",
    "for aggregator in ['Avg','Best']:\n",
    "    print('Evaluation with {}'.format(aggregator))\n",
    "    apply_avg = aggregator == 'Avg'\n",
    "    apply_best = aggregator == 'Best'\n",
    "\n",
    "    evaluator = rouge.Rouge(metrics=['rouge-n'],\n",
    "                           max_n=4,\n",
    "                           limit_length=True,\n",
    "                           length_limit=100,\n",
    "                           length_limit_type='words',\n",
    "                           apply_avg=apply_avg,\n",
    "                           apply_best=apply_best,\n",
    "                           alpha=0.5, # Default F1_score\n",
    "                           weight_factor=1.2,\n",
    "                           stemming=True)\n",
    "\n",
    "    scores = evaluator.get_scores(hypothesis, reference)\n",
    "    for metric, results in sorted(scores.items(), key=lambda x: x[0]):\n",
    "        print(prepare_results(results['p'], results['r'], results['f']))\n",
    "    print()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
